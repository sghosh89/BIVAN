---
title: "Unit tests"
author: "Shyamolina Ghosh and Daniel Reuman"
date: "March 7, 2018"
output: pdf_document
---

<!--Basic setup-->
```{r setup, echo=F}
#Basic setup

#A function needed for caching
source("mtime.R")
```

# Test flexible copula tail dependency statistics
We here test the functions `Corbds`, `Pbds` and `D2bds`.

Set up some test data:
```{r test_copula_function_flexible_data, echo=T}
dl<-seq(from=0.1,by=0.1,to=0.9)
ep<-c(.05,-.03,.02,-.1,-.09,.05,.1,-.08,.05)
vi<-dl+ep
vj<-dl-ep
```

A plot function to use in testing:
```{r plot_vivj,echo=T}
plot_vivj<-function(vi,vj,lb,ub){
plot(vi,vj,col="red",xlim=c(0,1),ylim=c(0,1),asp=1,cex.axis=0.5)
axis(1, at = seq(0, 1, by = 0.1),cex.axis=0.5)
abline(a=2*lb,b=-1,col="blue")
abline(a=2*ub,b=-1,col="green4")
abline(a=0,b=1)
rect(0,0,1,1)
}
```

Test the `Corbds` function:
```{r test_copula_function_flexible_cor, echo=T}
source("CopulaFunctions_flexible.R")
lb=.05
ub=.45
plot_vivj(vi,vj,lb,ub)
h<-Corbds(vi,vj,lb=lb,ub=ub)
inds<-1:4
ht<-sum((vi[inds]-mean(vi))*(vj[inds]-mean(vj)))/((length(vi)-1)*sqrt(var(vi)*var(vj)))

if (abs(h-ht)<1e-12)
{
  print("passed")
}
```

Test the `D2bds` function:
```{r test_copula_function_flexible_D2, echo=T}
source("CopulaFunctions_flexible.R")
lb=.05
ub=.45
h<-D2bds(vi,vj,lb=lb,ub=ub)
if (abs((sum(ep[1:4]^2)/2)-h)<1e-12)
{
  print("passed")
}
```

Test the `Pbds` function:
```{r test_copula_function_flexible_P, echo=T}
source("CopulaFunctions_flexible.R")

vi<-c(vi[3],vi[7],vi[9])
vj<-c(vj[3],vj[7],vj[9])

#Test the case in which the two parallel boundary lines are on the left side 
#of the vi+vj=1 line
lb=0
ub=.45
plot_vivj(vi=vi,vj=vj,lb=lb,ub=ub)
hl<-Pbds(vi,vj,lb=lb,ub=ub)

#plot the step function output - should have one jump at a small distance
#due to the one data point that is between the bound lines
plot(hl$dist_S,hl$S,type="b")

#calculate the area under the curve, compare to what the function returns 
vertices<-unique(hl$dist_S[(hl$dist_S!=0)])
area_S<-(vertices[2]-vertices[1])*1
if (abs(area_S-hl$Au_S)<1e-12)
{
  print("passed")
} else
{
  print("Au_S incorrectly computed")
}
  
#check P stat value for lower tail
if (abs(area_S-hl$Au_Si-hl$abs_res)<1e-12)
{
  print("passed")
} else
{
  print("Error in Pbds, the P stat")
}

#Test the case in which the two parallel boundary lines are on the right side 
#of the vi+vj=1 line
lb=0
ub=.45 
plot_vivj(vi=vi,vj=vj,lb=(1-ub),ub=(1-lb))

#calling P stat for upper tail
hu<-Pbds(vi,vj,lb=(1-ub),ub=(1-lb))

#hl$Au_Si should be the same as hu$Au_Si
if (abs(hl$Au_Si-hu$Au_Si)<1e-12)
{
  print("passed")
}else
{
  print("Error in Pbds, Au_Si")
}

#plot the step fn - should have two jumps
plot(hu$dist_S,hu$S,type="b")

#calculate the area under the curve 
w1<-unique(hu$dist_S[(hu$dist_S!=0)])
w1  #x-coords where the jumps occur, and the max dist
h1<-unique(hu$S)
h1  #y-coords of the above points
area_S<-((w1[2]-w1[1])*(h1[2]-h1[1]))+((w1[3]-w1[2])*(h1[3]-h1[1]))
if (abs(area_S-hu$Au_S)<1e-12)  
{
  print("passed")
} else
{
  print("Au_S incorrectly computed")
}

#P stat value for upper tail
if (abs(area_S-hu$Au_Si-hu$abs_res)<1e-12)
{
  print("passed")
}else
{
  print("P stat incorrectly computed")
}

#Test for the case in which the two parallel boundary lines are on opposite 
#sides of vi+vj=1 line
lb<-0.28
ub<-0.8

#calling P stat for middle section
hm<-Pbds(vi,vj,lb=lb,ub=ub)

#(vi,vj) plot in unit box : middle section
plot_vivj(vi=vi,vj=vj,lb=lb,ub=ub)

#plot the step fn
plot(hm$dist_S,hm$S,type="b")

#calculate the area under the curve 
w1<-unique(hm$dist_S[(hm$dist_S!=0)])
w1  #x-coord where the jump occurs
h1<-unique(hm$S)
h1  #y-coord where the jump occurs
area_S<-((w1[2]-w1[1])*(h1[2]-h1[1]))+((w1[3]-w1[2])*(h1[3]-h1[1]))
if (abs(area_S-hm$Au_S)<1e-12) 
{
  print("passed")
}else
{
  print("Error")
}

#P stat value for middle section
if (abs(area_S-hm$Au_Si-hm$abs_res)<1e-12)
{
  print("passed")
}else
{
  print("Error")
}
```

# Test skewness and third central moment functions

We here test the function `my3cm`, which is an unbiased estimator of the 3rd central moment:
```{r test_myskewness, echo=T, cache=T, cache.extra=list(mtime("SkewnessAnd3CentMom.R"))}
source("SkewnessAnd3CentMom.R")
set.seed(101)

x<-rnorm(100000)
my3cm(x) #should be close to 0

x<-rpois(100000,5)
#should be close to 5, but not necessarily super close
#since 3rd moments are hard to estimate accurately
my3cm(x) 

#see if it appears unbaised
res<-NA*numeric(1000)
for (counter in 1:1000)
{
  x<-rpois(100000,5)
  res[counter]<-my3cm(x) 
}
hist(res)
mean(res)
```

No need to test the accompanying skewness function, since it is such a simple extension of the above.

# Test surrogate functions

Test the `copsurrog2d` function:
```{r test_copsurrog2d, echo=T}
library("VineCopula")
source("copsurrog2d.R")
set.seed(101)

#***basic tests of the function using kendall-preserving surrogates
datcop<-claytonCopula(5,2)
numpts<-1000
m<-rCopula(numpts,datcop)
plot(m[,1],m[,2],type='p',asp=1)
rect(0,0,1,1)

tarcop<-gumbelCopula(3,2)

res<-copsurrog2d(m,tarcop,'kendall',3)
dim(res) 
if (sum(dim(res)[1:2]==dim(m))==2)
{
  print("passed")
} else
{
  print("dim of output is wrong")
}

cor(m[,1],m[,2],method='kendall') #this should be similar to the following 
cor(res[,1,1],res[,2,1],method='kendall')
cor(res[,1,2],res[,2,2],method='kendall')
cor(res[,1,3],res[,2,3],method='kendall')

plot(res[,1,1],res[,2,1],type='p',asp=1) #should look like a Gumbel
rect(0,0,1,1)
BiCopGofTest(res[,1,1],res[,2,1],family=4) #should indicate an acceptable fit; 
                                            #family=4 is Gumbel
BiCopGofTest(res[,1,2],res[,2,2],family=4) #should indicate an acceptable fit
BiCopGofTest(res[,1,3],res[,2,3],family=4) #should indicate an acceptable fit

if (sum(sort(res[,1,1])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,1])==sort(m[,2]))==numpts &&
    sum(sort(res[,1,2])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,2])==sort(m[,2]))==numpts &&
    sum(sort(res[,1,3])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,3])==sort(m[,2]))==numpts)
{
  print("passed")
} else
{
  print("Columns of output of copsurrog should be permutations of the corresponding 
        columns of the input")
}

#***basic tests using spearman preserving surrogates
res<-copsurrog2d(m,tarcop,'spearman',3)
dim(res)
if (sum(dim(res)[1:2]==dim(m))==2)
{
  print("passed")
} else
{
  print("dim of output is wrong")
}

cor(m[,1],m[,2],method='spearman') #this should be similar to the following 
cor(res[,1,1],res[,2,1],method='spearman')
cor(res[,1,2],res[,2,2],method='spearman')
cor(res[,1,3],res[,2,3],method='spearman')

plot(res[,1,1],res[,2,1],type='p',asp=1) #should look like a Gumbel
rect(0,0,1,1)
BiCopGofTest(res[,1,1],res[,2,1],family=4) #should indicate an acceptable fit; 
                                            #family=4 is Gumbel
BiCopGofTest(res[,1,2],res[,2,2],family=4) #should indicate an acceptable fit
BiCopGofTest(res[,1,3],res[,2,3],family=4) #should indicate an acceptable fit

if (sum(sort(res[,1,1])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,1])==sort(m[,2]))==numpts &&
    sum(sort(res[,1,2])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,2])==sort(m[,2]))==numpts &&
    sum(sort(res[,1,3])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,3])==sort(m[,2]))==numpts)
{
  print("passed")
} else
{
  print("Columns of output of copsurrog should be permutations of the corresponding columns of the input")
}
```

Test `copsurrog2d` to see whether changing the copula
markedly influences the distribution
of the spatial mean:
```{r test_copsurrog2d_spatmean, echo=T, cache=T, cache.extra=list(mtime("copsurrog2d.R"),mtime("SkewnessAnd3CentMom.R"))}
set.seed(101)

#make the data
datcop<-rotCopula(claytonCopula(5,2))
d<-rCopula(10000,datcop)
d<-qnorm(d,mean=0,sd=1)

#change the copula
tarcop<-claytonCopula(3,2)
sur<-copsurrog2d(d,tarcop,"kendall",1000)

#see how the skewness of the spatial average
#is affected
source("SkewnessAnd3CentMom.R")
skdat<-myskns(apply(FUN=mean,X=d,MARGIN=1)) #skewness of spatial mean of data
mnres<-apply(FUN=mean,X=sur,MARGIN=c(1,3)) 
sksur<-apply(FUN=myskns,X=mnres,MARGIN=2) #skewnesses of spatial means of surrogate 
                                          #datasets
sum(sksur<skdat)/length(sksur) #skewnesses of surrogs should be less than that of data
range(sksur) #these should mostly be negative
skdat #this should be positive

#now do the same thing but preserve the spearman instead
sur<-copsurrog2d(d,tarcop,"spearman",1000)
skdat<-myskns(apply(FUN=mean,X=d,MARGIN=1))
mnres<-apply(FUN=mean,X=sur,MARGIN=c(1,3))
sksur<-apply(FUN=myskns,X=mnres,MARGIN=2)
sum(sksur<skdat)/length(sksur) #skewnesses of surrogs should be less than that of data
range(sksur) #these should mostly be negative
```

Test the `ncsurrog` function:
```{r test_ncsurrog, echo=T, cache=T, cache.extra=list(mtime("ncsurrog.R"))}
source("ncsurrog.R")
set.seed(103)

#test without NAs
cop<-claytonCopula(5,3)
numpts<-1000
m<-rCopula(numpts,cop)
plot(m[,1],m[,2],type='p',asp=1)
rect(0,0,1,1)
plot(m[,1],m[,3],type='p',asp=1)
rect(0,0,1,1)
res<-ncsurrog(m,"kendall",3)
if (sum(dim(res)==c(1000,3,3))==3)
{
  print("passed")
} else
{
  print("dimension wrong in ncsurrog output")
}

plot(res[,1,1],res[,2,1],type='p',asp=1)
rect(0,0,1,1) #should look like a normal copula
plot(res[,1,1],res[,3,1],type='p',asp=1)
rect(0,0,1,1) #should look like a normal copula

#these should show an adequate fit
ncop<-normalCopula(.5,2)
BiCopGofTest(res[,1,1],res[,2,1],family=1)
BiCopGofTest(res[,1,2],res[,2,2],family=1)
BiCopGofTest(res[,1,3],res[,2,3],family=1)

#test with NAs
m[sample(1:numpts,5),1]<-NA
m[sample(1:numpts,5),2]<-NA
m[sample(1:numpts,5),3]<-NA
res<-ncsurrog(m,"kendall",3)
if (sum(dim(res)==c(1000,3,3))==3)
{
  print("passed")
} else
{
  print("dimension wrong in ncsurrog output")
}

sum(is.na(res[,1,1])) #these should all be 5
sum(is.na(res[,2,1]))
sum(is.na(res[,1,2]))
sum(is.na(res[,2,2]))

plot(res[,1,1],res[,2,1],type='p',asp=1)
rect(0,0,1,1) #should look like a normal copula
plot(res[,1,1],res[,3,1],type='p',asp=1)
rect(0,0,1,1) #should look like a normal copula

#these should show an adequate fit
BiCopGofTest(res[,1,1],res[,2,1],family=1)
BiCopGofTest(res[,1,2],res[,2,2],family=1)
BiCopGofTest(res[,1,3],res[,2,3],family=1)
```

Test the `copsurrognd` function:
```{r test_copsurrognd, echo=T, cache=T, cache.extra=list(mtime("copsurrognd.R"))}
library("VineCopula")
source("copsurrognd.R")
set.seed(101)

#basic tests
datcop<-claytonCopula(3,dim=3)
numpts<-1000
m<-rCopula(numpts,datcop)
plot(m[,1],m[,2],type='p',asp=1)
rect(0,0,1,1)
plot(m[,1],m[,3],type='p',asp=1)
rect(0,0,1,1)
plot(m[,2],m[,3],type='p',asp=1)
rect(0,0,1,1)

tarcop<-gumbelCopula(8,dim=3)

res<-copsurrognd(m=m,targetcop=tarcop,numsurrog=5)
if (sum(dim(res)[1:2]==dim(m))==2)
{
  print("passed")
} else
{
  print("dim of output is wrong")
}

cor(res[,1,1],res[,2,1],method="kendall")
cor(res[,1,1],res[,3,1],method="kendall")
cor(res[,2,1],res[,3,1],method="kendall") #these should be similar to each other and to the following... 

gd<-rCopula(1000,tarcop)
cor(gd[,1],gd[,2],method="kendall")
cor(gd[,1],gd[,3],method="kendall")
cor(gd[,2],gd[,3],method="kendall")

#but not to these, because correlations match the target, not the original data
cor(m[,1],m[,2],method='kendall')  
cor(m[,1],m[,3],method='kendall')  
cor(m[,2],m[,3],method='kendall') 

plot(res[,1,1],res[,2,1],type='p',asp=1) #should look like a Gumbel
rect(0,0,1,1)
plot(res[,1,1],res[,3,1],type='p',asp=1) #should look like a Gumbel
rect(0,0,1,1)
plot(res[,2,1],res[,3,1],type='p',asp=1) #should look like a Gumbel
rect(0,0,1,1)
BiCopGofTest(res[,1,1],res[,2,1],family=4) #should indicate an acceptable fit; 
                                            #family=4 is Gumbel
BiCopGofTest(res[,1,1],res[,3,1],family=4) #should indicate an acceptable fit
BiCopGofTest(res[,2,1],res[,3,1],family=4) #should indicate an acceptable fit

if (sum(sort(res[,1,1])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,1])==sort(m[,2]))==numpts &&
    sum(sort(res[,3,1])==sort(m[,3]))==numpts &&
    sum(sort(res[,1,2])==sort(m[,1]))==numpts &&
    sum(sort(res[,2,2])==sort(m[,2]))==numpts &&
    sum(sort(res[,3,2])==sort(m[,3]))==numpts)
{
  print("passed")
} else
{
  print("Columns of output of copsurrog should be permutations of the corresponding 
        columns of the input")
}
```

# Tests of model selection tool

We here test the `OurBiCopSelect` function with simulated data.

Data are simulated from a Clayton copula with parameter 8:
```{r get_data_test, echo=T}
source("getcopula.R")
source("OurBiCopSelect.R")
set.seed(101)
cop<-claytonCopula(8,2)
d<-rCopula(1000,cop)
v<-getcopula(d=d,rankon=F,ploton=T) #with real data, rankon should be T
```

Now apply the function:
```{r bivmodselect_test, echo=F, cache=T, cache.extra=list(d,mtime("OurBiCopSelect.R"))}
families<-c(1,3,4,5,13)
BivMS_res_test<-OurBiCopSelect(d[,1],d[,2],families=families,gofnormal=T,status=TRUE)
```

Independence should be rejected (low $p$ value):
```{r echo=T}
BivMS_res_test$IndepTestRes
```

Tau value should be positive:
```{r echo=T}
BivMS_res_test$TauVal
```

Model selection should support the actual model (Clayton):
```{r echo=T}
BivMS_res_test$InfCritRes
```

The actual model (Clayton) should not be rejected:
```{r echo=T}
BivMS_res_test$GofRes_CvM
BivMS_res_test$GofRes_KS
```

Look at goodness-of-fit results for the normal copulas:
```{r echo=T}
BivMS_res_test$GofRes_Normal_CvM
BivMS_res_test$GofRes_Normal_KS
```

We decided not to use the goodness-of-fit tests for normal copulas (`gofnormal=F` henceforth)
because it takes so long, and the model-selection results give 
sufficient indication that the normal copula is not well supported. 
Finally, in other simulations we have discovered the goodness-of-fit
tests for the normal copula have limited statistical power.

Now test with negatively correlated data, which happens ocassionally:

Data are simulated from a normal copula with parameter $-0.2$:
```{r get_neg_dat, echo=T}
set.seed(101)
cop<-normalCopula(-0.2,2,dispstr="un")
d<-rCopula(1000,cop)
v<-getcopula(d=d,rankon=F,ploton=T) #with real data, rankon should be T
```

Make sure the correlatation is negative for these data:
```{r test_neg_dat, echo=T}
cor(v[,1],v[,2],method="kendall")
```

Call `OurBiCopSelect` - all is should do is test independence, reject independence,
get tau and find it negative and then stop:
```{r test_OurBiCopSelect_neg, echo=T, cache=T, cache.extra=list(v,mtime("OurBiCopSelect.R"))}
res<-OurBiCopSelect(v[,1],v[,2],families=c(1,3,9),level=0.05,AICBIC="AIC",
                         numBSsmall=100,pthresh=0.2,numBSlarge=1000,
                         gofnormal=F,status=TRUE)
res
```

# Tests for retd() function from ExtremeTailDep.R

DCR to add this section

# Tests for mydispersal.R

**Test for `Dispersal_mat` function** 

```{r test_for_Dispersal_mat}
source("mydispersal.R")
set.seed(101)
D1<-Dispersal_mat(numlocs=3,d=0.4,disp_everywhere=F)
D1  #matrix for dispersion between nearest neighbours in a linear chain model
D2<-Dispersal_mat(numlocs=3,d=0.4,disp_everywhere=T) 
D2  #matrix for dispersion between any nodes in a linear chain model
if((isSymmetric.matrix(D1)==F) & (isSymmetric.matrix(D2)==T)){print("Dispersal_mat : passed")} 
```

**Test for `popsim_ml_D`  and `extrisk` function**
<!-- I assume here that retd() function is already checked and passed the test
#-------Args--------------------------------------------------
#p0       A length numlocs vector holding initial populations
#ns       An numsims by numlocs by numsteps array of the epsilons, 
#           where numsteps is the number of time steps you want
#
#--------Output------------------------------------------------------
#A numsims by numlocs by numsteps+1 array of populations
#----------------------------------------------------------------------
popsim_ml_D<-function(p0,ns,D,r,K)
-->
```{r test_for_popsim_ml_D, echo=T}
source("mydispersal.R")
set.seed(101)
numsteps<-15
numsims<-4
numlocs<-3
  
ns1<-retd(n=numsteps*numsims,d=numlocs,rl=1) # output from ExtremeTailDep.R : 
#                                                      a righttail dep matrix(numpoints by numlocs,     
#                                                      numpoints=numsteps*numsims)
dim(ns1)
ns1<-array(ns1,c(numsteps,numsims,numlocs))# convert to an array (numsteps by numsims by numlocs)
if(all(dim(ns1)==c(numsteps,numsims,numlocs))==T){print("passed")}
ns1<-aperm(ns1,c(2,3,1)) # convert to an array (numsims by numlocs by numsteps)
if(all(dim(ns1)==c(numsims,numlocs,numsteps))==T){print("passed")}

D<-D1
r<-0.5
K<-10
res<-popsim_ml_D(p0=rep(K,numlocs),ns=ns1,D=D1,r=r,K=K)
res[,,1]
res[,,2]
res[,,numsteps+1]
if(all(dim(res)==c(numsims,numlocs,numsteps+1))==T){print("popsim_ml_D : passed")}

# test for extrisk function
totpop<-apply(FUN=sum,X=res,MARGIN=c(1,3))
totpop # numsims by numsteps+1 matrix
if(all(totpop[,1]==(numlocs*K))==T){print("passed")}
ext<-(apply(FUN=sum,X=(totpop==0),MARGIN=2)/dim(res)[1])
ext
if(length(ext)==numsteps+1){print("passed")}

ans<-extrisk(sims=res)
if(all(ext==ans)==T){print("extrisk : passed")}
```

# Tests for Cause4copula.R

**Test for `GetNoise` function**

```{r test_GetNoise, echo=T}
set.seed(seed=101)
source("Cause4copula.R")
# Here we generate noise with 5000 points drawn from Clayton copula with Kendall's tau=0.5 
s<-GetNoise(N=5000,fcode=3,corcoef=0.5,method="kendall",ploton=T) # plot in copula space
s1<-s$noise_q
hist(s1[,1],breaks=1000) # This should be normal distribution
hist(s1[,2],breaks=1000) # This should be normal distribution
plot(s1[,1],s1[,2],col="red") # plot after qnorm

# Here we also checked C or SC copula 
# with same spearman's rho/ kendall's tau have same parameter
tgcop<-claytonCopula(3,2)
tgcop2<-rotCopula(tgcop)
iRho(tgcop,0.5)==iRho(tgcop2,0.5) # check if it is True?
iTau(tgcop,0.5)==iTau(tgcop2,0.5) # check if it is True?
```

**Test for `Simulator_Cause4copula` and `comp` function**

```{r test_Simulator_Cause4copula, echo=T}
set.seed(seed=101)
source("Cause4copula.R")
# when noise comes from a clayton cop with spearmancor=0.8
s<-GetNoise(N=5000,fcode=3,corcoef=0.8,method="spearman",ploton=T) # noise copula
s2<-Simulator_Cause4copula(cons=0.5,p0=c(0,0),noise=s$noise_q)
points(s2$pop_c[,1],s2$pop_c[,2],col="green") # population copula
hist(s2$pop_q[,1],breaks=1000) # check if it's normal
hist(s2$pop_c[,1],breaks=1000) # check if it's uniform
num_keep_last<-500
zz<-comp(s=s,s2=s2,num_keep_last=num_keep_last)
zz$comp
x<-c(dim(zz$last_num_keep_noise$last_num_keep_noise_c)[1],
     dim(zz$last_num_keep_noise$last_num_keep_noise_q)[1],
     dim(zz$last_num_keep_pop$last_num_keep_pop_c)[1],
     dim(zz$last_num_keep_pop$last_num_keep_pop_c)[1])
if(all(x==num_keep_last)){
  print("passed")
}else{
  print("failed")
}
```





















